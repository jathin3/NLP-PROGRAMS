{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqNVJNwLC42AjAAMW6MFMi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jathin3/NLP-PROGRAMS/blob/master/PDF%20Text%20Extraction%20%20and%20%20FAISS%20Search%20Pipeline\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYpkaRLF9TLo"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import PyPDF2\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "# Function to download the PDF from a URL\n",
        "def download_pdf_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return BytesIO(response.content)  # Return PDF as in-memory file\n",
        "    else:\n",
        "        raise Exception(f\"Failed to download PDF. HTTP Status Code: {response.status_code}\")\n",
        "# Extract text from PDF\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    text = \"\"\n",
        "    reader = PyPDF2.PdfReader(pdf_file)\n",
        "    for page in reader.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:  # Only append if text exists\n",
        "            text += page_text + \"\\n\"\n",
        "    return text\n",
        "# Chunk the text into smaller pieces\n",
        "def chunk_text(text, chunk_size=512):\n",
        "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "# Convert text chunks to embeddings\n",
        "def embed_chunks(chunks):\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    embeddings = model.encode(chunks, convert_to_tensor=False)  # Get embeddings as a NumPy array\n",
        "    return np.array(embeddings)\n",
        "# Store embeddings in FAISS index\n",
        "def store_embeddings(embeddings):\n",
        "    dimension = embeddings.shape[1]  # Embedding dimension\n",
        "    index = faiss.IndexFlatL2(dimension)  # L2 Distance-based index\n",
        "    index.add(embeddings)  # Add embeddings to the index\n",
        "    return index\n",
        "# Main function to orchestrate everything\n",
        "def main():\n",
        "    # URL of the PDF\n",
        "    pdf_url = \"https://www.hunter.cuny.edu/dolciani/pdf_files/workshop-materials/mmc-presentations/tables-charts-and-graphs-with-examples-from.pdf/at_download/file\"\n",
        "    try:\n",
        "        # Step 1: Download the PDF\n",
        "        pdf_file = download_pdf_from_url(pdf_url)\n",
        "        print(\"PDF downloaded successfully.\")\n",
        "\n",
        "        # Step 2: Extract text\n",
        "        text = extract_text_from_pdf(pdf_file)\n",
        "        print(\"Text extracted successfully.\")\n",
        "        # Step 3: Chunk the text\n",
        "        chunks = chunk_text(text)\n",
        "        print(f\"Text chunked into {len(chunks)} parts.\")\n",
        "        # Step 4: Convert text chunks to embeddings\n",
        "        embeddings = embed_chunks(chunks)\n",
        "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
        "        # Step 5: Store embeddings in FAISS\n",
        "        index = store_embeddings(embeddings)\n",
        "        print(\"Embeddings stored successfully in FAISS index.\")\n",
        "        # Example: Query the FAISS index (optional)\n",
        "        print(\"Querying the FAISS index with the first embedding...\")\n",
        "        distances, indices = index.search(embeddings[:1], k=3)  # Find 3 nearest neighbors\n",
        "        print(\"Nearest neighbors:\", indices)\n",
        "        print(\"Distances:\", distances)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "# Run the program\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}